{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "753dc38b",
   "metadata": {},
   "source": [
    "# All Models, All Features (Except Secondary Structure), One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c3149b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas      : 1.4.4\n",
      "numpy       : 1.23.3\n",
      "scikit-learn: 1.1.2\n",
      "matplotlib  : 3.5.3\n",
      "\n",
      "conda environment: hotspot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,scikit-learn,matplotlib --conda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b8b23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa4e343",
   "metadata": {},
   "source": [
    "# 1) Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9950b961",
   "metadata": {},
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fe36649",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../dataset/TrainingDataset.csv')\n",
    "df_test = pd.read_csv('../dataset/TestDataset.csv')\n",
    "\n",
    "# 1 & 2 -> 1\n",
    "# 0 -> 0\n",
    "\n",
    "binarized = df_train['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_train['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "binarized = df_test['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_test['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "\n",
    "y_train = df_train['2-class-merged-v1'].values\n",
    "y_test = df_test['2-class-merged-v1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e316bc",
   "metadata": {},
   "source": [
    "## Use Sequence-Only Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8fc283e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
       "       'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['residue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b49f1779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert aa char to int\n",
    "codes = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', \n",
    "         'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['residue'] = df_train['residue'].map(code_to_int)\n",
    "df_test['residue'] = df_test['residue'].map(code_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d568f980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-', 'H', 'S', 'T'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['secondary structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32fdb7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert secondary structure char to int\n",
    "codes = ['H', 'S', 'T', '-']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['secondary structure'] = df_train['secondary structure'].map(code_to_int)\n",
    "df_test['secondary structure'] = df_test['secondary structure'].map(code_to_int)\n",
    "\n",
    "feature_list = ['residue', 'consurf', 'secondary structure']\n",
    "\n",
    "df_train = df_train[feature_list]\n",
    "df_test = df_test[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30abf0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['residue'] = df_train['residue'].astype('category')\n",
    "df_test['residue'] = df_test['residue'].astype('category')\n",
    "\n",
    "df_train['secondary structure'] = df_train['secondary structure'].astype('category')\n",
    "df_test['secondary structure'] = df_test['secondary structure'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4f84e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "residue                category\n",
       "consurf                   int64\n",
       "secondary structure    category\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec5b680e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_list].values\n",
    "X_test =  df_test[feature_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "856fed1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2a8c0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5aefbf17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08f2dfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314,)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b13cfe5",
   "metadata": {},
   "source": [
    "## OneHot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af58cc01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(drop=&#x27;first&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "OneHotEncoder(drop='first')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "ohe.fit(df_train[feature_list][['residue', 'secondary structure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c0538e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ohe = df_train.drop(columns=['residue', 'secondary structure'])\n",
    "df_test_ohe = df_test.drop(columns=['residue', 'secondary structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a24fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train = np.asarray(ohe.transform(df_train[feature_list][['residue', 'secondary structure']]).todense())\n",
    "ohe_test = np.asarray(ohe.transform(df_test[feature_list][['residue', 'secondary structure']]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67416773",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = np.hstack((df_train_ohe.values, ohe_train))\n",
    "X_test_ohe = np.hstack((df_test_ohe.values, ohe_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44089be",
   "metadata": {},
   "source": [
    "# 2) Hyperparameter Tuning & Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cacae31",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62dea646",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae9720fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.54 +/- 0.05\n",
      "recall: 0.45 +/- 0.10\n",
      "f1: 0.49 +/- 0.07\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123))\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=pipe,\n",
    "        cv=10,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a25db6",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ac9b7b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.49331946128015014\n",
      "Best params {'logisticregression__C': 10, 'logisticregression__penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "100 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/pipeline.py\", line 382, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1233, in fit\n",
      "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 117, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 432, in _logistic_regression_path\n",
      "    l2_reg_strength = 1.0 / C\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sebastianraschka/miniforge3/envs/hotspot/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [       nan 0.                nan 0.                nan 0.43701603\n",
      "        nan 0.49037126        nan        nan        nan 0.48710414\n",
      "        nan 0.49331946        nan 0.49331946        nan 0.49331946]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV precision: 0.55 +/- 0.04\n",
      "10-fold CV recall: 0.45 +/- 0.09\n",
      "10-fold CV f1: 0.49 +/- 0.07\n",
      "Test precision: 0.62\n",
      "Test recall: 0.48\n",
      "Test f1: 0.54\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123, max_iter=1000))\n",
    "\n",
    "params =  {\n",
    "    'logisticregression__penalty':['l1', 'l2'],\n",
    "    'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 0.0, 1.0, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace0c73d",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0fcf0b",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "722a26f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.56 +/- 0.10\n",
      "recall: 0.53 +/- 0.07\n",
      "f1: 0.54 +/- 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=RandomForestClassifier(random_state=123, n_estimators=1000),\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847ffdde",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78235a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5352185095842519\n",
      "Best params {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 1000}\n",
      "10-fold CV precision: 0.61 +/- 0.09\n",
      "10-fold CV recall: 0.49 +/- 0.09\n",
      "10-fold CV f1: 0.54 +/- 0.07\n",
      "Test precision: 0.65\n",
      "Test recall: 0.46\n",
      "Test f1: 0.54\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(random_state=123))\n",
    "\n",
    "params =  {\n",
    "    'randomforestclassifier__max_depth': [3, 5, 10],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "    'randomforestclassifier__n_estimators': [1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb05a92",
   "metadata": {},
   "source": [
    "## HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "907a65fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5648596746225949\n",
      "Best params {'histgradientboostingclassifier__learning_rate': 1, 'histgradientboostingclassifier__max_leaf_nodes': 30}\n",
      "10-fold CV precision: 0.58 +/- 0.09\n",
      "10-fold CV recall: 0.55 +/- 0.08\n",
      "10-fold CV f1: 0.56 +/- 0.07\n",
      "Test precision: 0.57\n",
      "Test recall: 0.59\n",
      "Test f1: 0.58\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(HistGradientBoostingClassifier(random_state=123))\n",
    "\n",
    "params = {\n",
    "    'histgradientboostingclassifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'histgradientboostingclassifier__max_leaf_nodes': (3, 10, 30)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ad35d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm-seqonly.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from joblib import dump\n",
    "\n",
    "#dump([ohe, gs.best_estimator_], 'gbm-seqonly.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbf8d51a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm-seqonly-hotspotter.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_all_ohe = np.vstack((X_train_ohe, X_test_ohe))\n",
    "#y_all_ohe = np.hstack((y_train, y_test))\n",
    "\n",
    "#gs.best_estimator_.fit(X_all_ohe, y_all_ohe)\n",
    "\n",
    "#dump([ohe, gs.best_estimator_], 'gbm-seqonly-hotspotter.joblib') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc46ab90",
   "metadata": {},
   "source": [
    "## Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "880cd014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5567712545157372\n",
      "Best params {'svc__C': 100.0, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "10-fold CV precision: 0.58 +/- 0.09\n",
      "10-fold CV recall: 0.54 +/- 0.08\n",
      "10-fold CV f1: 0.56 +/- 0.07\n",
      "Test precision: 0.58\n",
      "Test recall: 0.57\n",
      "Test f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(random_state=123))\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "params = [{'svc__C': param_range, \n",
    "               'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, \n",
    "               'svc__gamma': param_range, \n",
    "               'svc__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cd4793",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a1cfcac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.554799788112198\n",
      "Best params {'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 0.0001, 'mlpclassifier__hidden_layer_sizes': (20,), 'mlpclassifier__learning_rate': 'constant', 'mlpclassifier__solver': 'adam'}\n",
      "10-fold CV precision: 0.56 +/- 0.08\n",
      "10-fold CV recall: 0.56 +/- 0.10\n",
      "10-fold CV f1: 0.55 +/- 0.07\n",
      "Test precision: 0.58\n",
      "Test recall: 0.57\n",
      "Test f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     MLPClassifier(max_iter=10000, random_state=123))\n",
    "\n",
    "\n",
    "params = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(30, 20, 10), \n",
    "                                          (40, 20), \n",
    "                                          (20, 10), \n",
    "                                          (20,),\n",
    "                                          (10,)],\n",
    "    'mlpclassifier__activation': ['tanh', 'relu'],\n",
    "    'mlpclassifier__solver': ['sgd', 'adam'],\n",
    "    'mlpclassifier__alpha': [0.0001, 0.001, 0.05],\n",
    "    'mlpclassifier__learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  n_jobs=-1,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "070948ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../hotspotter/mlp-seqfeatures.joblib']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump([ohe, gs.best_estimator_], '../../hotspotter/mlp-seqfeatures.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6ef243ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../../hotspotter/mlp-seqfeatures-alldata.joblib']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_all_ohe = np.vstack((X_train_ohe, X_test_ohe))\n",
    "y_all_ohe = np.hstack((y_train, y_test))\n",
    "\n",
    "gs.best_estimator_.fit(X_all_ohe, y_all_ohe)\n",
    "\n",
    "dump([ohe, gs.best_estimator_], '../../hotspotter/mlp-seqfeatures-alldata.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cb52ba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
