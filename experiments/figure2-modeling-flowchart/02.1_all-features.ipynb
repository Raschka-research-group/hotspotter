{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ec52659",
   "metadata": {},
   "source": [
    "# All Models, All Features, One-hot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3664e9",
   "metadata": {},
   "source": [
    "This notebook evaluates all models, including all features for the flowchart in Figure 2. The categorical features are encoded via one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a53d29e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "pandas      : 1.4.4\n",
      "numpy       : 1.23.3\n",
      "scikit-learn: 1.1.2\n",
      "matplotlib  : 3.5.3\n",
      "\n",
      "conda environment: hotspot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,scikit-learn,matplotlib --conda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "233d6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d2921e",
   "metadata": {},
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d6772fe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/TrainingDataset.csv')\n",
    "df_test = pd.read_csv('../datasets/3class-TestDataset.csv')\n",
    "\n",
    "# 1 & 2 -> 1\n",
    "# 0 -> 0\n",
    "\n",
    "binarized = df_train['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_train['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "binarized = df_test['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_test['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "\n",
    "y_train = df_train['2-class-merged-v1'].values\n",
    "y_test = df_test['2-class-merged-v1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50bfb8ad",
   "metadata": {},
   "source": [
    "## Use All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8f5f481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
       "       'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['residue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d7549bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert aa char to int\n",
    "codes = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', \n",
    "         'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['residue'] = df_train['residue'].map(code_to_int)\n",
    "df_test['residue'] = df_test['residue'].map(code_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09ccf180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-', 'H', 'S', 'T'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['secondary structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ff9beff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert secondary structure char to int\n",
    "codes = ['H', 'S', 'T', '-']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['secondary structure'] = df_train['secondary structure'].map(code_to_int)\n",
    "df_test['secondary structure'] = df_test['secondary structure'].map(code_to_int)\n",
    "\n",
    "feature_list = ['avg bond number', 'Hbond', 'residue',\n",
    "                'Hphob', 'consurf', \"B' side chain\", 'secondary structure', 'asa']\n",
    "\n",
    "df_train = df_train[feature_list]\n",
    "df_test = df_test[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1981ccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['residue'] = df_train['residue'].astype('category')\n",
    "df_test['residue'] = df_test['residue'].astype('category')\n",
    "\n",
    "df_train['secondary structure'] = df_train['secondary structure'].astype('category')\n",
    "df_test['secondary structure'] = df_test['secondary structure'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ce1e7e6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg bond number         float64\n",
       "Hbond                     int64\n",
       "residue                category\n",
       "Hphob                     int64\n",
       "consurf                   int64\n",
       "B' side chain           float64\n",
       "secondary structure    category\n",
       "asa                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42fec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_list].values\n",
    "X_test =  df_test[feature_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e0035bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 8)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7657f05a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd5588af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e3650780",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314,)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e6f16c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  3.],\n",
       "       [ 1.,  1.],\n",
       "       [14.,  3.],\n",
       "       ...,\n",
       "       [19.,  2.],\n",
       "       [14.,  2.],\n",
       "       [ 1.,  3.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, [2, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fecb1a8",
   "metadata": {},
   "source": [
    "## OneHot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f51c7e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(drop='first')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "ohe.fit(df_train[feature_list][['residue', 'secondary structure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9288567a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ohe = df_train.drop(columns=['residue', 'secondary structure'])\n",
    "df_test_ohe = df_test.drop(columns=['residue', 'secondary structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "220fca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train = np.asarray(ohe.transform(df_train[feature_list][['residue', 'secondary structure']]).todense())\n",
    "ohe_test = np.asarray(ohe.transform(df_test[feature_list][['residue', 'secondary structure']]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d8dae49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = np.hstack((df_train_ohe.values, ohe_train))\n",
    "X_test_ohe = np.hstack((df_test_ohe.values, ohe_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be040686",
   "metadata": {},
   "source": [
    "## Logistic Regression OneHot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ac603",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4e10121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.59 +/- 0.06\n",
      "recall: 0.59 +/- 0.07\n",
      "f1: 0.59 +/- 0.06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123))\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=pipe,\n",
    "        cv=10,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453d462c",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "912d1502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5926456848618582\n",
      "Best params {'logisticregression__C': 10, 'logisticregression__penalty': 'l2'}\n",
      "10-fold CV precision: 0.60 +/- 0.06\n",
      "10-fold CV recall: 0.59 +/- 0.07\n",
      "10-fold CV f1: 0.59 +/- 0.06\n",
      "Test precision: 0.64\n",
      "Test recall: 0.66\n",
      "Test f1: 0.65\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 811, in _logistic_regression_path\n",
      "    args=(X, target, 1.0 / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.                nan 0.24994688        nan 0.55666644\n",
      "        nan 0.58342652        nan        nan        nan 0.58911234\n",
      "        nan 0.59264568        nan 0.59264568        nan 0.59264568]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123, max_iter=1000))\n",
    "\n",
    "params =  {\n",
    "    'logisticregression__penalty':['l1', 'l2'],\n",
    "    'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 0.0, 1.0, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3046c9a2",
   "metadata": {},
   "source": [
    "## Random Forest OneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d53f6c",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1c130a70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.60 +/- 0.09\n",
      "recall: 0.54 +/- 0.13\n",
      "f1: 0.56 +/- 0.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=RandomForestClassifier(random_state=123, n_estimators=1000),\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48809f39",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fef0bcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5906457208838057\n",
      "Best params {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__min_samples_split': 2, 'randomforestclassifier__n_estimators': 1000}\n",
      "10-fold CV precision: 0.63 +/- 0.09\n",
      "10-fold CV recall: 0.56 +/- 0.10\n",
      "10-fold CV f1: 0.59 +/- 0.09\n",
      "Test precision: 0.64\n",
      "Test recall: 0.58\n",
      "Test f1: 0.61\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(random_state=123))\n",
    "\n",
    "params =  {\n",
    "    'randomforestclassifier__max_depth': [3, 5, 10],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "    'randomforestclassifier__n_estimators': [1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58bd4af2",
   "metadata": {},
   "source": [
    "## HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4a3ba900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5901880014966452\n",
      "Best params {'histgradientboostingclassifier__learning_rate': 0.01, 'histgradientboostingclassifier__max_leaf_nodes': 3}\n",
      "10-fold CV precision: 0.60 +/- 0.07\n",
      "10-fold CV recall: 0.58 +/- 0.09\n",
      "10-fold CV f1: 0.59 +/- 0.07\n",
      "Test precision: 0.62\n",
      "Test recall: 0.54\n",
      "Test f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(HistGradientBoostingClassifier(random_state=123))\n",
    "\n",
    "params = {\n",
    "    'histgradientboostingclassifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'histgradientboostingclassifier__max_leaf_nodes': (3, 10, 30)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdfd036",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "52888923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.616483605745531\n",
      "Best params {'svc__C': 1.0, 'svc__kernel': 'linear'}\n",
      "10-fold CV precision: 0.59 +/- 0.05\n",
      "10-fold CV recall: 0.64 +/- 0.08\n",
      "10-fold CV f1: 0.62 +/- 0.06\n",
      "Test precision: 0.61\n",
      "Test recall: 0.68\n",
      "Test f1: 0.65\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(random_state=123))\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "params = [{'svc__C': param_range, \n",
    "               'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, \n",
    "               'svc__gamma': param_range, \n",
    "               'svc__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933ec21a",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "451680a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5946984905511946\n",
      "Best params {'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 0.0001, 'mlpclassifier__hidden_layer_sizes': (20, 10), 'mlpclassifier__learning_rate': 'adaptive', 'mlpclassifier__solver': 'sgd'}\n",
      "10-fold CV precision: 0.60 +/- 0.06\n",
      "10-fold CV recall: 0.60 +/- 0.08\n",
      "10-fold CV f1: 0.59 +/- 0.07\n",
      "Test precision: 0.65\n",
      "Test recall: 0.68\n",
      "Test f1: 0.67\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     MLPClassifier(max_iter=10000, random_state=123))\n",
    "\n",
    "\n",
    "params = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(30, 20, 10), \n",
    "                                          (40, 20), \n",
    "                                          (20, 10), \n",
    "                                          (20,),\n",
    "                                          (10,)],\n",
    "    'mlpclassifier__activation': ['tanh', 'relu'],\n",
    "    'mlpclassifier__solver': ['sgd', 'adam'],\n",
    "    'mlpclassifier__alpha': [0.0001, 0.001, 0.05],\n",
    "    'mlpclassifier__learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  n_jobs=-1,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2d8a136d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.1_mlp_pipe.joblib']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(gs.best_estimator_, '01.1_mlp_pipe.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6b7da1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
