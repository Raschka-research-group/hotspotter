{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2fd310a",
   "metadata": {},
   "source": [
    "# All Models, All Features, Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24a6d1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas      : 1.4.4\n",
      "numpy       : 1.23.3\n",
      "scikit-learn: 1.1.2\n",
      "matplotlib  : 3.5.3\n",
      "\n",
      "conda environment: hotspot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,scikit-learn,matplotlib --conda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2862435",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb0f395",
   "metadata": {},
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73d4e060",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/TrainingDataset.csv')\n",
    "df_test = pd.read_csv('../datasets/3class-TestDataset.csv')\n",
    "\n",
    "# 1 & 2 -> 1\n",
    "# 0 -> 0\n",
    "\n",
    "binarized = df_train['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_train['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "binarized = df_test['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_test['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "\n",
    "y_train = df_train['2-class-merged-v1'].values\n",
    "y_test = df_test['2-class-merged-v1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a83ac932",
   "metadata": {},
   "source": [
    "## Use All Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d35a5b08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
       "       'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['residue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b637bba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert aa char to int\n",
    "codes = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', \n",
    "         'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['residue'] = df_train['residue'].map(code_to_int)\n",
    "df_test['residue'] = df_test['residue'].map(code_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48af4d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['-', 'H', 'S', 'T'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['secondary structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90de5966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert secondary structure char to int\n",
    "codes = ['H', 'S', 'T', '-']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['secondary structure'] = df_train['secondary structure'].map(code_to_int)\n",
    "df_test['secondary structure'] = df_test['secondary structure'].map(code_to_int)\n",
    "\n",
    "feature_list = ['avg bond number', 'Hbond', 'residue',\n",
    "                'Hphob', 'consurf', \"B' side chain\", 'secondary structure', 'asa']\n",
    "\n",
    "df_train = df_train[feature_list]\n",
    "df_test = df_test[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a60f0bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['residue'] = df_train['residue'].astype('category')\n",
    "df_test['residue'] = df_test['residue'].astype('category')\n",
    "\n",
    "df_train['secondary structure'] = df_train['secondary structure'].astype('category')\n",
    "df_test['secondary structure'] = df_test['secondary structure'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0efbc1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg bond number         float64\n",
       "Hbond                     int64\n",
       "residue                category\n",
       "Hphob                     int64\n",
       "consurf                   int64\n",
       "B' side chain           float64\n",
       "secondary structure    category\n",
       "asa                     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c717822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_list].values\n",
    "X_test =  df_test[feature_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9e717b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "796f7766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a0b52e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb470091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2702c85c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.,  3.],\n",
       "       [ 1.,  1.],\n",
       "       [14.,  3.],\n",
       "       ...,\n",
       "       [19.,  2.],\n",
       "       [14.,  2.],\n",
       "       [ 1.,  3.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, [2, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d150e114",
   "metadata": {},
   "source": [
    "## Target Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9952c94a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetEncoder()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dirty_cat import TargetEncoder\n",
    "\n",
    "enc = TargetEncoder(categories='auto', clf_type='binary-clf')\n",
    "enc.fit(df_train[feature_list][['residue', 'secondary structure']],\n",
    "        y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "659deb1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53006536, 0.44274376],\n",
       "       [0.46017334, 0.42806268],\n",
       "       [0.38758993, 0.44274376],\n",
       "       ...,\n",
       "       [0.45571537, 0.43303571],\n",
       "       [0.38758993, 0.43303571],\n",
       "       [0.46017334, 0.44274376]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.transform(df_train[feature_list][['residue', 'secondary structure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "610eeae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ohe = df_train.drop(columns=['residue', 'secondary structure'])\n",
    "df_test_ohe = df_test.drop(columns=['residue', 'secondary structure'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e623ce66",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train = enc.transform(df_train[feature_list][['residue', 'secondary structure']])\n",
    "ohe_test = enc.transform(df_test[feature_list][['residue', 'secondary structure']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c1d215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = np.hstack((df_train_ohe.values, ohe_train))\n",
    "X_test_ohe = np.hstack((df_test_ohe.values, ohe_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca1d4b90",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21d376a",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0a97e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.60 +/- 0.06\n",
      "recall: 0.56 +/- 0.11\n",
      "f1: 0.58 +/- 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123))\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=pipe,\n",
    "        cv=10,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80493f21",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "599e216b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5766408706974199\n",
      "Best params {'logisticregression__C': 1.0, 'logisticregression__penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 811, in _logistic_regression_path\n",
      "    args=(X, target, 1.0 / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.                nan 0.25205774        nan 0.55641034\n",
      "        nan 0.56930056        nan        nan        nan 0.57664087\n",
      "        nan 0.57664087        nan 0.57445833        nan 0.57445833]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV precision: 0.60 +/- 0.06\n",
      "10-fold CV recall: 0.56 +/- 0.11\n",
      "10-fold CV f1: 0.58 +/- 0.08\n",
      "Test precision: 0.63\n",
      "Test recall: 0.59\n",
      "Test f1: 0.61\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123, max_iter=1000))\n",
    "\n",
    "params =  {\n",
    "    'logisticregression__penalty':['l1', 'l2'],\n",
    "    'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 0.0, 1.0, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbcda5c",
   "metadata": {},
   "source": [
    "## Random Forest OneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e646c84",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5eafd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.59 +/- 0.08\n",
      "recall: 0.53 +/- 0.09\n",
      "f1: 0.56 +/- 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=RandomForestClassifier(random_state=123, n_estimators=1000),\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50398c7f",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "31e6897c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5915128287758064\n",
      "Best params {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 1000}\n",
      "10-fold CV precision: 0.62 +/- 0.07\n",
      "10-fold CV recall: 0.58 +/- 0.13\n",
      "10-fold CV f1: 0.59 +/- 0.09\n",
      "Test precision: 0.64\n",
      "Test recall: 0.58\n",
      "Test f1: 0.61\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(random_state=123))\n",
    "\n",
    "params =  {\n",
    "    'randomforestclassifier__max_depth': [3, 5, 10],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "    'randomforestclassifier__n_estimators': [1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ab535d",
   "metadata": {},
   "source": [
    "## HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e72b8eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5893115809151049\n",
      "Best params {'histgradientboostingclassifier__learning_rate': 0.1, 'histgradientboostingclassifier__max_leaf_nodes': 3}\n",
      "10-fold CV precision: 0.60 +/- 0.10\n",
      "10-fold CV recall: 0.59 +/- 0.16\n",
      "10-fold CV f1: 0.59 +/- 0.12\n",
      "Test precision: 0.62\n",
      "Test recall: 0.61\n",
      "Test f1: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(HistGradientBoostingClassifier(random_state=123))\n",
    "\n",
    "params = {\n",
    "    'histgradientboostingclassifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'histgradientboostingclassifier__max_leaf_nodes': (3, 10, 30)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb1302b",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "533d0270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.6040465114472755\n",
      "Best params {'svc__C': 1000.0, 'svc__gamma': 0.01, 'svc__kernel': 'rbf'}\n",
      "10-fold CV precision: 0.63 +/- 0.08\n",
      "10-fold CV recall: 0.59 +/- 0.10\n",
      "10-fold CV f1: 0.60 +/- 0.08\n",
      "Test precision: 0.62\n",
      "Test recall: 0.60\n",
      "Test f1: 0.61\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(random_state=123))\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "params = [{'svc__C': param_range, \n",
    "               'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, \n",
    "               'svc__gamma': param_range, \n",
    "               'svc__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9e9c2a",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aa19a8e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.618805623226676\n",
      "Best params {'mlpclassifier__activation': 'relu', 'mlpclassifier__alpha': 0.0001, 'mlpclassifier__hidden_layer_sizes': (40, 20), 'mlpclassifier__learning_rate': 'constant', 'mlpclassifier__solver': 'sgd'}\n",
      "10-fold CV precision: 0.62 +/- 0.05\n",
      "10-fold CV recall: 0.63 +/- 0.10\n",
      "10-fold CV f1: 0.62 +/- 0.07\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X_test_oh' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m score_name \u001b[38;5;129;01min\u001b[39;00m score_names:\n\u001b[1;32m     50\u001b[0m     scorer \u001b[38;5;241m=\u001b[39m sklearn\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mget_scorer(score_name)\n\u001b[0;32m---> 52\u001b[0m     score \u001b[38;5;241m=\u001b[39m scorer(gs\u001b[38;5;241m.\u001b[39mbest_estimator_, \u001b[43mX_test_oh\u001b[49m, y_test)\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mscore\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_test_oh' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     MLPClassifier(max_iter=10000, random_state=123))\n",
    "\n",
    "\n",
    "params = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(30, 20, 10), \n",
    "                                          (40, 20), \n",
    "                                          (20, 10), \n",
    "                                          (20,),\n",
    "                                          (10,)],\n",
    "    'mlpclassifier__activation': ['tanh', 'relu'],\n",
    "    'mlpclassifier__solver': ['sgd', 'adam'],\n",
    "    'mlpclassifier__alpha': [0.0001, 0.001, 0.05],\n",
    "    'mlpclassifier__learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  n_jobs=-1,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "60800732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test precision: 0.63\n",
      "Test recall: 0.66\n",
      "Test f1: 0.64\n"
     ]
    }
   ],
   "source": [
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38552736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27f2610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
