{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a82ba53",
   "metadata": {},
   "source": [
    "# All Models, All Features (Except Secondary Structure), One-hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6791cde4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas      : 1.4.4\n",
      "numpy       : 1.23.3\n",
      "scikit-learn: 1.1.2\n",
      "matplotlib  : 3.5.3\n",
      "\n",
      "conda environment: hotspot\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -p pandas,numpy,scikit-learn,matplotlib --conda "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c26ba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5f67a",
   "metadata": {},
   "source": [
    "## Binarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76602c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('../datasets/TrainingDataset.csv')\n",
    "df_test = pd.read_csv('../datasets/3class-TestDataset.csv')\n",
    "\n",
    "# 1 & 2 -> 1\n",
    "# 0 -> 0\n",
    "\n",
    "binarized = df_train['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_train['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "binarized = df_test['3-class'].values.copy()\n",
    "binarized[binarized == 2] = 1\n",
    "df_test['2-class-merged-v1'] = binarized.astype(int)\n",
    "\n",
    "\n",
    "y_train = df_train['2-class-merged-v1'].values\n",
    "y_test = df_test['2-class-merged-v1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6aac49e",
   "metadata": {},
   "source": [
    "## Use All Features (Except Secondary Structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a0f0382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M', 'N', 'P', 'Q',\n",
       "       'R', 'S', 'T', 'V', 'W', 'Y'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_train['residue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35bc7a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert aa char to int\n",
    "codes = ['A', 'R', 'N', 'D', 'C', 'E', 'Q', 'G', 'H', \n",
    "         'I', 'L', 'K', 'M', 'F', 'P', 'S', 'T', 'W', 'Y', 'V']\n",
    "code_to_int = {c:i for i,c in enumerate(codes)}     \n",
    "df_train['residue'] = df_train['residue'].map(code_to_int)\n",
    "df_test['residue'] = df_test['residue'].map(code_to_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "887ea754",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['avg bond number', 'Hbond', 'residue',\n",
    "                'Hphob', 'consurf', \"B' side chain\", 'asa']\n",
    "\n",
    "df_train = df_train[feature_list]\n",
    "df_test = df_test[feature_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb8561a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['residue'] = df_train['residue'].astype('category')\n",
    "df_test['residue'] = df_test['residue'].astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b61891e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "avg bond number     float64\n",
       "Hbond                 int64\n",
       "residue            category\n",
       "Hphob                 int64\n",
       "consurf               int64\n",
       "B' side chain       float64\n",
       "asa                 float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df05d7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train[feature_list].values\n",
    "X_test =  df_test[feature_list].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f74d170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f755afc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(732,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f74bc7f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a9086b7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(314,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d025a339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.   ,  2.089],\n",
       "       [ 1.   ,  0.637],\n",
       "       [14.   ,  0.226],\n",
       "       ...,\n",
       "       [19.   ,  0.872],\n",
       "       [14.   ,  0.147],\n",
       "       [ 1.   ,  0.   ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:, [2, 6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499a8297",
   "metadata": {},
   "source": [
    "## OneHot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "339288f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneHotEncoder(drop='first')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(drop='first')\n",
    "ohe.fit(df_train[feature_list][['residue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f751584",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_ohe = df_train.drop(columns=['residue'])\n",
    "df_test_ohe = df_test.drop(columns=['residue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b7d95aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_train = np.asarray(ohe.transform(df_train[feature_list][['residue']]).todense())\n",
    "ohe_test = np.asarray(ohe.transform(df_test[feature_list][['residue']]).todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d3fa7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ohe = np.hstack((df_train_ohe.values, ohe_train))\n",
    "X_test_ohe = np.hstack((df_test_ohe.values, ohe_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa2e630",
   "metadata": {},
   "source": [
    "## Logistic Regression OneHot Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e4cf21",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85317c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.60 +/- 0.07\n",
      "recall: 0.59 +/- 0.10\n",
      "f1: 0.59 +/- 0.08\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123))\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=pipe,\n",
    "        cv=10,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0cbff",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8845ef7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5895873408981294\n",
      "Best params {'logisticregression__C': 1.0, 'logisticregression__penalty': 'l2'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "100 fits failed out of a total of 180.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "90 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1461, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 447, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "10 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/pipeline.py\", line 394, in fit\n",
      "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1589, in fit\n",
      "    fold_coefs_ = Parallel(\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 1043, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/joblib/parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/utils/fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 811, in _logistic_regression_path\n",
      "    args=(X, target, 1.0 / C, sample_weight),\n",
      "ZeroDivisionError: float division by zero\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/sebastian/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.                nan 0.24337175        nan 0.55601568\n",
      "        nan 0.58583687        nan        nan        nan 0.58958734\n",
      "        nan 0.58718297        nan 0.58718297        nan 0.58718297]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10-fold CV precision: 0.60 +/- 0.07\n",
      "10-fold CV recall: 0.59 +/- 0.10\n",
      "10-fold CV f1: 0.59 +/- 0.08\n",
      "Test precision: 0.62\n",
      "Test recall: 0.64\n",
      "Test f1: 0.63\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats\n",
    "import sklearn\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     LogisticRegression(random_state=123, max_iter=1000))\n",
    "\n",
    "params =  {\n",
    "    'logisticregression__penalty':['l1', 'l2'],\n",
    "    'logisticregression__C': [0.0001, 0.001, 0.01, 0.1, 0.0, 1.0, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccf9a91",
   "metadata": {},
   "source": [
    "## Random Forest OneHot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355b68cd",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e268fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.58 +/- 0.09\n",
      "recall: 0.55 +/- 0.10\n",
      "f1: 0.56 +/- 0.10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=RandomForestClassifier(random_state=123, n_estimators=1000),\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    \n",
    "    print(f'{score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfa2be1",
   "metadata": {},
   "source": [
    "### Tuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8e730eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.6013455875548332\n",
      "Best params {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__min_samples_split': 5, 'randomforestclassifier__n_estimators': 1000}\n",
      "10-fold CV precision: 0.65 +/- 0.09\n",
      "10-fold CV recall: 0.57 +/- 0.11\n",
      "10-fold CV f1: 0.60 +/- 0.10\n",
      "Test precision: 0.65\n",
      "Test recall: 0.61\n",
      "Test f1: 0.62\n"
     ]
    }
   ],
   "source": [
    "pipe = make_pipeline(RandomForestClassifier(random_state=123))\n",
    "\n",
    "params =  {\n",
    "    'randomforestclassifier__max_depth': [3, 5, 10],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5, 10],\n",
    "    'randomforestclassifier__n_estimators': [1000],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa8cc1e",
   "metadata": {},
   "source": [
    "## HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "93025096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.5901880014966452\n",
      "Best params {'histgradientboostingclassifier__learning_rate': 0.01, 'histgradientboostingclassifier__max_leaf_nodes': 3}\n",
      "10-fold CV precision: 0.60 +/- 0.07\n",
      "10-fold CV recall: 0.58 +/- 0.09\n",
      "10-fold CV f1: 0.59 +/- 0.07\n",
      "Test precision: 0.62\n",
      "Test recall: 0.54\n",
      "Test f1: 0.57\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(HistGradientBoostingClassifier(random_state=123))\n",
    "\n",
    "params = {\n",
    "    'histgradientboostingclassifier__learning_rate': (0.01, 0.1, 1, 10),\n",
    "    'histgradientboostingclassifier__max_leaf_nodes': (3, 10, 30)\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc230570",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "097288cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.6127299234831669\n",
      "Best params {'svc__C': 1000.0, 'svc__gamma': 0.0001, 'svc__kernel': 'rbf'}\n",
      "10-fold CV precision: 0.59 +/- 0.07\n",
      "10-fold CV recall: 0.64 +/- 0.11\n",
      "10-fold CV f1: 0.61 +/- 0.08\n",
      "Test precision: 0.60\n",
      "Test recall: 0.66\n",
      "Test f1: 0.63\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(), SVC(random_state=123))\n",
    "\n",
    "param_range = [0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0]\n",
    "\n",
    "params = [{'svc__C': param_range, \n",
    "               'svc__kernel': ['linear']},\n",
    "              {'svc__C': param_range, \n",
    "               'svc__gamma': param_range, \n",
    "               'svc__kernel': ['rbf']}]\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1631ef",
   "metadata": {},
   "source": [
    "## Multilayer Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c62e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV F1 score 0.6013410072407404\n",
      "Best params {'mlpclassifier__activation': 'tanh', 'mlpclassifier__alpha': 0.0001, 'mlpclassifier__hidden_layer_sizes': (20,), 'mlpclassifier__learning_rate': 'adaptive', 'mlpclassifier__solver': 'sgd'}\n",
      "10-fold CV precision: 0.60 +/- 0.05\n",
      "10-fold CV recall: 0.61 +/- 0.09\n",
      "10-fold CV f1: 0.60 +/- 0.06\n",
      "Test precision: 0.61\n",
      "Test recall: 0.63\n",
      "Test f1: 0.62\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "pipe = make_pipeline(StandardScaler(),\n",
    "                     MLPClassifier(max_iter=10000, random_state=123))\n",
    "\n",
    "\n",
    "params = {\n",
    "    'mlpclassifier__hidden_layer_sizes': [(30, 20, 10), \n",
    "                                          (40, 20), \n",
    "                                          (20, 10), \n",
    "                                          (20,),\n",
    "                                          (10,)],\n",
    "    'mlpclassifier__activation': ['tanh', 'relu'],\n",
    "    'mlpclassifier__solver': ['sgd', 'adam'],\n",
    "    'mlpclassifier__alpha': [0.0001, 0.001, 0.05],\n",
    "    'mlpclassifier__learning_rate': ['constant', 'adaptive'],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params, \n",
    "                  scoring='f1', \n",
    "                  refit=True,\n",
    "                  n_jobs=-1,\n",
    "                  cv=10)\n",
    "\n",
    "gs = gs.fit(X_train_ohe, y_train)\n",
    "print('CV F1 score', gs.best_score_)\n",
    "print('Best params', gs.best_params_)\n",
    "\n",
    "\n",
    "score_names = ['precision', 'recall', 'f1']\n",
    "\n",
    "\n",
    "for score_name in score_names:\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        X=X_train_ohe,\n",
    "        y=y_train,\n",
    "        estimator=gs.best_estimator_,\n",
    "        cv=10,\n",
    "        n_jobs=-1,\n",
    "        scoring=score_name\n",
    "    )\n",
    "    print(f'10-fold CV {score_name}: {np.mean(scores):.2f} +/- {np.std(scores):.2f}')\n",
    "\n",
    "    \n",
    "for score_name in score_names:\n",
    "    \n",
    "    scorer = sklearn.metrics.get_scorer(score_name)\n",
    "    \n",
    "    score = scorer(gs.best_estimator_, X_test_ohe, y_test)\n",
    "    print(f'Test {score_name}: {score:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd0f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['01.4_mlp_pipe.joblib']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "dump(gs.best_estimator_, '01.4_mlp_pipe.joblib') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a0281",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
